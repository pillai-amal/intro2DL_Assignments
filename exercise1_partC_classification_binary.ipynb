{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will perform classification on a simple dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate the dataset with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "(X, y) = make_blobs(n_samples=5000, n_features=2, centers=2,\n",
    "cluster_std=3.5, random_state=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X and y are the features and the label, respectively. We can look at the format of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(5000, 2)\n",
      "(5000,)\n",
      "float64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(type(y))\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(X.dtype)\n",
    "print(y.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, X and y are numpy arrays. There are a total of 5000 samples in the dataset. X has 2 features per sample, and y are the corresponding classes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with a dataset, it is always helpful to visualize the data that we are working with, in order to be able to check if our results are meaningful. We will use matplotlib to plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X[:, 0], X[:, 1], marker=\"x\", c=y)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the two clusters are not linearily separable, but a linear classification would still yield good results. Your tasks in this notebook are now:\n",
    "\n",
    "- Add and adapt your regression code (using numpy, not sklearn) from the previous exercise, so that is can predict the class label for each sample. This means, we treat the class of a point (0 or 1) as the target value of the regression. The linear regression will then yield us a formula that can give each (x, y) location a score, which class it might belong to. It's not a probability because it does not need to be between 0 and 1, but we can interpret a value being nearer to 0 as a higher probability for the class 0, and a value being nearer to 1 as a higher probability for class 1.\n",
    "- â€¯ (e.g. yellow for class 0, blue for class 1).\n",
    "- Calculate the classification accurracy $\\left( \\frac{n_{\\text{correctly-classified}}}{(n_{\\text{correctly-classified}} + n_{\\text{incorrectly-classified}})} \\right) $\n",
    "- Bonus: If everything works, you will see that your classification splits the dataset at a specific line between the two clusters. Calculate the formula for this line and plot it as a line using matplotlib.\n",
    "- After you have done the iris classification exercise, print out the [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) using sklearn for this binary classification task. Then, plot the precision-recall curve using [precision_recall_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve) and matplotlib\n",
    "- Bonus: After you have done all the above, write your own code to calculate the metrics shown in classification_report and use that code to generate the precision-recall curve manually."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 62.62 %\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m, (acc_prediction\u001b[39m/\u001b[39m(acc_prediction \u001b[39m+\u001b[39m inacc_prediction)\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m), \u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[39m#plotting\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m plt\u001b[39m.\u001b[39mplot(prediction)\n\u001b[1;32m     33\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "\n",
    "#parameters\n",
    "alpha = 0.01  # learning rate\n",
    "num_iters = 1000  # number of iterations\n",
    "\n",
    "# initialising the coffecients for muliple leear regression\n",
    "coeffs = np.zeros(X.shape[1])\n",
    "\n",
    "# gradient descent algorithm\n",
    "for i in range(num_iters):\n",
    "    # Compute predictions and errors\n",
    "    y_pred = np.dot(X, coeffs)\n",
    "    errors = y_pred - y\n",
    "    \n",
    "    # Update coefficients\n",
    "    gradient = np.dot(X.T, errors) / X.shape[0]\n",
    "    coeffs -= alpha * gradient\n",
    "\n",
    "# making a list of predictions using linear regression formula y = w1.x1 + w2.x2 for multiple linear regression\n",
    "prediction = [1 if (np.sum(coeffs*X[i,:]) > 1) else 0 for i in range(int(X[:].shape[0]))]\n",
    "\n",
    "# defining two metrics for calculating accuracy, here we check the delta between given labels and our predictions\n",
    "acc_prediction = np.sum([1 if ((y[i] - prediction[i]) == 0) else 0 for i in range(len(prediction))]) # adding the zero deltas as accurate\n",
    "inacc_prediction = np.sum([1 if ((y[i] - prediction[i]) == 1) else 0 for i in range(len(prediction))]) # adding the non zero as inaccurate\n",
    "\n",
    "#printing the final accuracy of the linear regression classifier\n",
    "print('Accuracy', (acc_prediction/(acc_prediction + inacc_prediction)*100), '%')\n",
    "\n",
    "#plotting\n",
    "plt.plot(prediction)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
